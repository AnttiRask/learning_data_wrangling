---
title: "6 Working with DateTime"
author: "Gustavo R. Santos (original) | Antti Rask (modifications)"
date: "2022-07-14"
output: html_document
---

# Working with Date and Time Objects

## Import libraries and Load Dataset

```{r, message=FALSE, warning=FALSE}
library(conflicted) # An Alternative Conflict Resolution Strategy
  conflicts_prefer(dplyr::filter)
  conflicts_prefer(dplyr::lag)
library(hms)        # Pretty Time of Day
library(tidyverse)  # Easily Install and Load the 'Tidyverse'
```

## Introduction

There are three main ways to work with datetime objects in data science.
1. You create them
2. You parse them from a string or text
3. Arithmetic operations

---

### 1. Creating a Date or datetime objects

Computers register date and time in their systems. As convention, computers compute any date and time objects using January 1st, 1970 at 00:00:00 UTC.

You can check the current date and time from your system using __{lubridate}__.

```{r}
# Checking today's system date
"today()"
today()

# Checking current system's time
"now()"
now()

# Creating a date object
"as_date(0)"
as_date(0)

"ymd()"
ymd(20220714)

"mdy()"
mdy("Jul142022")

"yq()"
yq("2010Q4")

# Creating a time object
"as_hms()"
as_hms(43200)

"ymd_hms()"
ymd_hms(20220714150000)

# Creating a datetime object one year after 1970-01-1
#(60s*60min*24h*365d = 31,536,000 seconds)
"as_datetime()"
as_datetime(31536000)
```

#### Datetime to Date

Dropping time portion of a datetime object.

```{r}
# Datetime object
dt_tm <- ymd_hm("2022-01-02 03:04")

# Convert to just date object
as_date(dt_tm)
```

### 2. Parsing datetime objects from strings or text

When dealing with datetime objects in a text or data frame and you want to parse or split the dates, use the following commands.

```{r}

# Creating a variable with 4 dates
dt <- c(
  "2000-01-01 01:01:01",
  "2005-02-02 02:02:02",
  "2010-03-03 03:03:03",
  "2020-04-04 04:04:04"
)

# Assign it as datetime object
dt <- as_datetime(dt)

### From a variable of dates, split them ###

# years
year(dt)

# months
month(dt)

# weeks
week(dt)

#week day
wday(dt)

# days
day(dt)

# hours
hour(dt)

# minutes
minute(dt)

# seconds
second(dt)

# time zones
tz(dt)
```

#### Gather date/ time objects

```{r}
# Separate variables
y_obj <- "2022"
m_obj <- "5"
d_obj <- "10"

# gather date
str_c(y_obj, m_obj, d_obj, sep = "-") %>% 
  ymd()
```

### 3. Arithmetic Operations

Arithmetic operations with datetime are slightly more complex than operations with real numbers. The complexity comes from different units and specific properties, such as time zones.

If we add 20 days to Jan 10, we get to the 30th. But if we add it to Feb, we will land in March, for example.

```{r}
# Simple subtraction
dt1 <- as_date("2022-06-01")
dt2 <- as_date("2022-05-01")

dt1 - dt2
```

To comprehend this, we must understand periods, durations and intervals.
* Period: tracks changes in time, not accounting for any deviations.
* Duration: tracks passage of time, accounting for deviations like gaps.
* Interval: a time interval composed by start and end.

### Period

```{r}
# Date
dt <- ymd("2000-01-01")

# Date minus a past date
today() - dt
```

```{r}
# Create a period to add or subtract
p <- years(x = 22) + months(x = 06) + days(x = 13)

# Another syntax
p <- period(c(22, 6, 13), c("year","month", "day"))

p
```

```{r}
# Operations
dt + p
dt - p
```

```{r}
# Date of the last maintenance
dt <- ymd("2021-01-15")

# Create a period to add or subtract
p <- years(x=1) + months(x=06) + days(x=1)

# Another syntax
p <- period( c(1, 6, 1), c("year","month", "day"))

# Calculation
cat(str_c("Next maintenance date is on: ", dt + p))
```

### Duration

```{r}
# Date
dt <- ymd("2000-01-01")

# Create a duration of 5 years
dw <- dyears(x = 5)

dw
```

```{r}
# Calculate warranty time 5 years after dt
warranty_end <- dt + dw

cat(str_c("Warranty ends on: ", warranty_end))
```

### Interval

```{r}
# Date
dt <- ymd("2022-01-01")

# Interval start
i <- interval(start = "2021-01-01", end = "2022-12-31")
i
```

```{r}
# Date within interval
dt %within% i
```

### Time Zone

```{r}
# System time zone
Sys.timezone()

# Creating a datetime object in another timezone
ymd_hms("2022-01-01 00:00:00")
ymd_hms("2022-01-01 00:00:00", tz = "Europe/Paris")

#--Display datetime in different time zone--

# Date creation
dt_dubai <- ymd_hms("2022-07-01 10:00:00", tz = "Asia/Dubai")
with_tz(dt_dubai, tzone="America/New_York")
```

## Datetime in text

Parsing datetime objects from text.

```{r}
# Lubridate parsing
mdy("The championship starts on 10/11-2000")
```

## Parsing with Regex

```{r}
# Text
t <- "The movie was launched on 10/10/1980. It was a great hype at that time, being the most watched movie on the weeks of 10/10/1980, 10/17/1980, 10/24/1980. Around ten years later, it was chosen as the best picture of the decade. The cast received the prize on 09/20/1990."

# Parse using regex
str_extract_all(t, "[0-9]+/[0-9]+/[0-9]+") %>%
  unlist() %>%
  mdy()
```

# Practice

The dataset to be used in this exercise is the Classic Rock, from fivethirtyeight.

To access the original dataset, got to: https://github.com/fivethirtyeight/data/tree/master/classic-rock

```{r}
# URL where the data is stored
url <- "https://raw.githubusercontent.com/fivethirtyeight/data/master/classic-rock/classic-rock-raw-data.csv"

# Load to RStudio
tbl <- read_csv(url)

# Make a copy of the original data
tbl_original <- tbl

# View data frame in RStudio viewer
View(tbl)
```

Transform column time in datetime.

You may have just seen that the column time brings integer numbers.

To be able to work with these dates, we must, first, transform that variable to a datetime variable.

```{r}
# Variable TIME to datetime
tbl_with_dates <- tbl %>% 
  mutate(TIME = TIME %>% as_datetime())

tbl_with_dates
```

For our purpose, there is no need of all the variables. Let"s select some.

```{r}
# Select variables
tbl_selected <- tbl_with_dates %>% 
  select(
    "Song Clean",
    "ARTIST CLEAN",
    CALLSIGN,
    TIME,
    COMBINED,
    "First?"
  )

tbl_selected
```

Next, we are creating some extra granularity for time, by adding columns for month, day, week day and hour for further analysis.

Notice that year is always 2014 and month is 06, so no point in keeping them.

```{r}
tbl_augmented <- tbl_selected %>%
  
  mutate(
    
    # Add new column year
    year    = year(TIME),
    
    # Add new column month
    month   = month(TIME),
    
    # Add new column day
    day     = day(TIME),
    
    # Add new column week day
    weekday = wday(TIME),
    
    # Add new column hour
    hour    = hour(TIME)
  ) %>% 
  select(-c(year, month))

tbl_augmented
```

## Visualizations

Since now we have many slices of time, we can create many different views of the musics using that data.

What is the distribution of musics played per day of the week?

```{r}
# Filter only unique observations
tbl_unique <- tbl_augmented %>%
  distinct(
    `Song Clean`,
    .keep_all = TRUE
  )

# Songs by weekday
song_by_wkd <- tbl_unique %>%
  count(weekday)

# Bar plot of Songs by weekday
song_by_wkd %>%
  ggplot(aes(as.factor(weekday), n)) +
  geom_col(fill = "royalblue", color = "black") +
  scale_y_continuous(
    breaks = seq(0, 600, by = 100),
    expand = c(0, 0),
    limits = c(0, 600)
  ) +
  labs(
    title = "Number of unique songs by day of the week",
    x     = "Day of the Week [1=Sun, 7=Sat]",
    y     = "Distinct Songs"
  ) +
  theme_classic() +
  theme(
    axis.line.x  = element_blank(),
    axis.ticks.x = element_blank()
  )
```

What is the hour when there are more music being played?

In this case, I don't need to filter only distinct song, as I really want to know what is the most busy hour of those days.

```{r}
# Songs by hour
song_by_hour <- tbl_augmented %>%
  count(hour)

# Bar plot of Songs by hour
song_by_hour %>%
  ggplot(aes(as.factor(hour), n)) +
  geom_col(fill = "royalblue", color = "black") +
  scale_x_discrete(breaks = seq(0, 23, by = 1)) +
  scale_y_continuous(
    breaks = seq(0, 8000, by = 2000),
    expand = c(0, 0),
    limits = c(0, 9000)) +
  labs(
    title = "Songs by hour",
    x     = "Hour",
    y     = "Songs Played"
  ) +
  theme_classic() +
  theme(
    axis.line.x  = element_blank(),
    axis.ticks.x = element_blank()
  )
```

It looks like there is something weird going on at 11pm, or 23 hours. Let's filter that and have a closer look, just like in a real life project.

```{r}
# Filter and arrange only songs played at 23h
tbl_23 <- tbl_augmented %>% 
  filter(hour == 23) %>% 
  arrange(`Song Clean`, CALLSIGN, TIME)

tbl_23
```

A first verification can be searching for duplicate entries.

```{r}
# Checking if there are duplicated rows
tbl_23 %>% 
  distinct() %>%
  nrow() %>%
  {dim(tbl_23)[1] - .} # Anonymous function to compare the number of rows in the original dataset vs. now
```

Here's what's going on in the second filter in this next code chunk:

* pmap_lgl(): This function applies a function to each row of the dataset and returns a logical vector (a vector of TRUE and FALSE values). The function to be applied is specified using a formula notation with the tilde (~) symbol.
* all(.x == lag(.x, n = 1)): The all() function checks if all the elements in a logical vector are TRUE. In this case, it checks if all the elements of the current row (.x) are equal to the elements of the previous row (lag(.x, n = 1)). The lag() function shifts the elements of the row by 1 position (specified by n = 1). If all the elements are equal, all() returns TRUE; otherwise, it returns FALSE.
* filter(): This function is used to subset the dataset based on a condition. In this case, the condition is the logical vector generated by pmap_lgl(). Rows with TRUE values in the logical vector are retained in the dataset.

```{r}
# Filter only the duplicated rows
dups <- tbl_23 %>%
  filter(duplicated(tbl_23))

# Test for real duplicates
real_dup <- dups %>%
  mutate(row_number = row_number()) %>%
  filter(pmap_lgl(dups, ~ all(.x == lag(.x, n = 1)))) %>%
  pull(row_number)

# Look at duplicates
dups %>%
  filter(row_number() %in% c(9, 81))

# Checking duplicates
tbl_original %>% 
  filter(
    TIME == ymd_hms("2014-06-19 23:54:25") & COMBINED %in% c(
      "Another One Bites the Dust by Queen",
      "Fly Like an Eagle by Steve Miller Band"
    )
  )
```

```{r}
# Remove duplicates
tbl <- tbl_original %>%
  filter(!UNIQUE_ID %in% c("WCSX0949", "WCSX1021", "WCSX0955", "WCSX1005")) %>%

# Select variables and manipulate TIME variable
  select(
    song_clean   = "Song Clean",
    artist_clean = "ARTIST CLEAN",
    call_sign    = CALLSIGN,
    time         = TIME,
    combined     = COMBINED, 
    first        = "First?"
  ) %>%
  mutate(
    time    = as_datetime(time),
    year    = year(time),
    month   = month(time),
    day     = day(time),
    weekday = wday(time),
         hour    = hour(time)
  )

tbl
```

Everything looks fine. What happened is that we summed all the songs played by hour for all the days in that week. A better approach should be grouping the dataset by day and take an average of songs played by hour.

```{r}
# Group data by weekday
tbl_by_day <- tbl %>% 
  summarise(
    songs_ct = n(),
    .by = c(weekday, hour)
  ) %>% 

# Group the result by hour
  summarize(
    avg_songs_ct = mean(songs_ct),
    .by = hour
  )

# Line plot of Songs by weekday
tbl_by_day %>%
  ggplot(aes(hour, avg_songs_ct)) +
  geom_line(color = "royalblue", linewidth = 1.5) +
  scale_y_continuous(
    breaks = seq(0, 1200, by = 200),
    expand = c(0, 0)
  ) +
  labs(
    title = "Avg Number of Songs Played by Hour",
    x     = "Hour",
    y     = "Songs Played") +
  theme_classic()
```

Even then, the number of songs played at 11pm is really high.

Now, let's see what hour has most songs being played for the first time.

```{r}
# Filter only first time = 1
first_time <- tbl %>%
  filter(first == 1)

# First Time Songs by Hour
first_time <- first_time %>% 
  summarise(
    song_count = n(),
    .by        = hour
  )

# Line plot of First appearance Songs by hour
first_time %>%
  ggplot(aes(hour, song_count)) +
  geom_line(color = "royalblue", linewidth = 1.5) +
  scale_y_continuous(
    breaks = seq(0, 500, by = 100),
    expand = c(0, 0),
    limits = c(0, 500)
  ) +
  labs(
    title = "First Time Played by Hour",
    x     = "Hour",
    y     = "Songs Played") +
  theme_classic()
```

Average Number of songs played by radio by day

```{r}
# Average by radio by day
by_radio <- tbl %>% 
  summarise(
    song_count = n(),
    .by = c(call_sign, weekday)
  ) %>% 
  summarise(
    avg_song = mean(song_count),
    .by = call_sign
  ) %>% 
  arrange(desc(avg_song)) %>%
  head(5)

# Bar Plot
by_radio %>% 
  mutate(call_sign = as.factor(call_sign)) %>%
  ggplot(aes(fct_reorder(call_sign, avg_song), avg_song)) +
  geom_col(fill = "royalblue", color = "black") +
  coord_flip() +
  scale_y_continuous(
    breaks = seq(0, 300, by = 50),
    expand = c(0, 0),
    limits = c(0, 320)
  ) +
  labs(
    title = "Average Number of Songs by Radio Station in a Day",
    x     = "Radio Station",
    y     = "Avg Number of Songs Played"
  ) +
  theme_classic()
```
